{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3ZeWciiqBRB"
      },
      "source": [
        "# **CityLife Dataset - MOT validation**\n",
        "1. Using ByteTrack as a SoTA multiobject tracker - (Some of the scripts here were taken from the ByteTrack Colab)\n",
        "2. Validation using PyMot\n",
        "\n",
        "Hyper-parameters setup:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0qp1V66powb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "\n",
        "# ignore small boxes (to skip box filtering in inference time set to zero)\n",
        "min_box_side = 0\n",
        "min_box_area = max(100, min_box_side ** 2)\n",
        "min_segmentation_pixels = 10\n",
        "\n",
        "dataset_root_on_gdrive = '/content/drive/MyDrive/.../Citylife/'\n",
        "dump_path = os.path.join(dataset_root_on_gdrive, 'CityLife_randomwalk_128_v6_10fps')\n",
        "print(f'Dataset: {dump_path}')\n",
        "\n",
        "# download the dataset into 'dump_path'\n",
        "!gdown --id \"<put download key here>\"\n",
        "\n",
        "gt_json_path = os.path.join(dump_path, 'peds_bbox.json')\n",
        "output_dir = os.path.join(dataset_root_on_gdrive, 'ByteTrackPred')\n",
        "frame_rate = 10\n",
        "\n",
        "# mount gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQ98fFTvtB4i"
      },
      "source": [
        "# **Init data and model**\n",
        "Download ByteTrack, install dependencies etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NgJ5uSqQvuv"
      },
      "outputs": [],
      "source": [
        "# mount drive\n",
        "import sys\n",
        "import json\n",
        "from shutil import rmtree, copytree, copyfile\n",
        "from google.colab import drive\n",
        "\n",
        "drive_path = '/content/drive' \n",
        "drive.mount(drive_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCVvFCX6z03x"
      },
      "outputs": [],
      "source": [
        "# == Download the ByteTrack repo content and install dependencies ==\n",
        "!git clone https://github.com/ifzhang/ByteTrack.git\n",
        "%cd /content/ByteTrack/\n",
        "%mkdir pretrained\n",
        "%cd pretrained\n",
        "\n",
        "# == Download pretrained X model weights ==\n",
        "!gdown --id \"1P4mY0Yyd3PPTybgZkjMYhFri88nTmJX5\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46hQmpmo0Wby"
      },
      "outputs": [],
      "source": [
        "# == Install dependencies ==\n",
        "!pip3 install cython\n",
        "!pip3 install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "!pip3 install cython_bbox\n",
        "\n",
        "%cd /content/ByteTrack/\n",
        "!pip3 install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcuzq_MJ1EmK"
      },
      "outputs": [],
      "source": [
        "# == Install ByteTrack ==\n",
        "!python3 setup.py develop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNEjogF5s35O"
      },
      "source": [
        "# **Looping CityLife!**\n",
        "Track the videos/images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uHB47ppsy5F"
      },
      "outputs": [],
      "source": [
        "# recreate the output directory\n",
        "def recreate_dir(parent, dir_name):\n",
        "    \"\"\"deletes dir if exist and creates a folder dir_name under parent - thread safe\"\"\"\n",
        "    dir_path = os.path.join(parent, dir_name)\n",
        "    if os.path.isdir(dir_path):\n",
        "        rmtree(dir_path)\n",
        "    os.makedirs(dir_path, exist_ok=True)\n",
        "    return dir_path\n",
        "\n",
        "print(f'recreated output dir at: {recreate_dir(*os.path.split(output_dir))}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBQFUjdVwEJ3"
      },
      "outputs": [],
      "source": [
        "# Copy images to split folders\n",
        "def create_dir_if_not_exist(parent, dir_name):\n",
        "    \"\"\"creates a folder dir_name under parent if is does not exist already - thread safe\"\"\"\n",
        "    dir_path = os.path.join(parent, dir_name)\n",
        "    if not os.path.isdir(dir_path):\n",
        "        os.makedirs(dir_path, exist_ok=True)\n",
        "    return dir_path\n",
        "  \n",
        "png_dirs_dir_name = 'cams_images'\n",
        "png_dirs_dir_path = os.path.join(output_dir, png_dirs_dir_name)\n",
        "print(f'Start copying pngs to {png_dirs_dir_path}')\n",
        "rgb_frames_dir = os.path.join(dump_path, 'rgb')\n",
        "pngs = [os.path.join(rgb_frames_dir, f) for f in os.listdir(rgb_frames_dir) if f.endswith('png')]\n",
        "for png in pngs:\n",
        "  file_name = os.path.basename(png)\n",
        "  frame_fields = file_name.split('_')\n",
        "  cam_id = int(frame_fields[1])\n",
        "  frame_id = int(frame_fields[2])\n",
        "  cam_dir = create_dir_if_not_exist(png_dirs_dir_path, f'cam_{cam_id}')\n",
        "\n",
        "  # keeping order instead of lexicographical order\n",
        "  file_name = f'{frame_fields[0]}_{cam_id:05d}_{frame_id:05d}_' + '_'.join(frame_fields[3:])\n",
        "\n",
        "  target_path = os.path.join(cam_dir, file_name)\n",
        "  if os.path.isfile(target_path):\n",
        "    continue\n",
        "  copyfile(png, target_path)\n",
        "print('Done!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JpLojXTqs1n0"
      },
      "outputs": [],
      "source": [
        "# looping the dataset\n",
        "from shutil import copyfile, rmtree, copytree\n",
        "import subprocess\n",
        "\n",
        "for cam_dir_name in os.listdir(png_dirs_dir_path):\n",
        "  cam_dir_path = os.path.join(png_dirs_dir_path, cam_dir_name)\n",
        "  print('#'*100)\n",
        "  print(f'\\nStart tracking: {cam_dir_path}')\n",
        "\n",
        "  cam_id = int(os.path.basename(cam_dir_path).split('_')[1])\n",
        "  video_name = os.path.basename(cam_dir_path)\n",
        "\n",
        "  # run byte track\n",
        "  os.chdir('/content/ByteTrack')\n",
        "  if min_box_area > 0:\n",
        "    !python3 tools/demo_track.py image -f exps/example/mot/yolox_x_mix_det.py -c pretrained/bytetrack_x_mot17.pth.tar --path $cam_dir_path --min_box_area $min_box_area --fp16 --fuse --save_result &> log.txt --camid $cam_id --fps $frame_rate\n",
        "  else:\n",
        "    !python3 tools/demo_track.py image -f exps/example/mot/yolox_x_mix_det.py -c pretrained/bytetrack_x_mot17.pth.tar --path $cam_dir_path --fp16 --fuse --save_result &> log.txt --camid $cam_id --fps $frame_rate\n",
        "\n",
        "  import re\n",
        "  %cd /content/ByteTrack\n",
        "  with open('log.txt', 'r') as file_reader:\n",
        "    text = file_reader.read().replace('\\n', '')\n",
        "\n",
        "  m = re.search('save results to ./(.+?).txt', text)\n",
        "  if m:\n",
        "    png_repo_found = '/content/ByteTrack/' + m.group(1)\n",
        "    print(f'found vis: {png_repo_found}')\n",
        "  if not png_repo_found:\n",
        "    print(f'ERROR: failed compiling into a video on: {png_repo_found}')\n",
        "  destination_dir = os.path.join(output_dir, f'boxed_pngs_vis_{video_name}')\n",
        "  if os.path.isdir(destination_dir):\n",
        "    rmtree(destination_dir)\n",
        "  copytree(png_repo_found, destination_dir)\n",
        "\n",
        "  # == Get result prediction file path ==\n",
        "  pred_found = png_repo_found + \".txt\"\n",
        "  print(f'found pred: {pred_found}')\n",
        "\n",
        "  if not pred_found:\n",
        "    print(f'ERROR: failed retrieving the prediction file on: {pred_found}')\n",
        "  copyfile(pred_found, os.path.join(output_dir, f'pred_{video_name}.txt'))\n",
        "print('DONE!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Or03tZIRe9rN"
      },
      "source": [
        "# **Estimate Ground Truth from Segmentation Maps into MOT15**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpLiJfJ3ML-R"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class box_cmap:\n",
        "  def __init__(self, x: int, y: int, w: int, h: int, segment_freq: int) -> None:\n",
        "      self.x = x\n",
        "      self.y = y\n",
        "      self.w = w\n",
        "      self.h = h\n",
        "      self.freq = segment_freq\n",
        "\n",
        "  def __repr__(self) -> str:\n",
        "      return f'Box(x: {self.x}, y: {self.y}, w: {self.w}, h: {self.h})'\n",
        "\n",
        "  def area(self):\n",
        "    return self.w * self.h\n",
        "\n",
        "\n",
        "def image_to_boxes_by_color_loop(image_path: str):\n",
        "  \"\"\"take a colormap segmentation image and infer the bounding boxes by color\"\"\"\n",
        "  if not os.path.isfile(image_path):\n",
        "    raise Exception(f'File not found: {image_path}')\n",
        "  im = Image.open(image_path)\n",
        "  pixels = im.load()\n",
        "  width, height = im.size\n",
        "  rgb_to_stat = dict()\n",
        "\n",
        "  # TODO: Vectorize!\n",
        "  for x in range(width):\n",
        "    for y in range(height):\n",
        "      box_color = pixels[x, y]\n",
        "\n",
        "      # ignore BG color (green)\n",
        "      if box_color[0] == 55 and box_color[1] == 181 and box_color[2] == 57:\n",
        "        continue\n",
        "\n",
        "      if box_color in rgb_to_stat:\n",
        "        existing_box = rgb_to_stat[box_color]\n",
        "        x2 = max(existing_box.x + existing_box.w, x)\n",
        "        y2 = max(existing_box.y + existing_box.h, y)\n",
        "\n",
        "        existing_box.x = min(existing_box.x, x)\n",
        "        existing_box.y = min(existing_box.y, y)\n",
        "\n",
        "        existing_box.w = x2 - existing_box.x\n",
        "        existing_box.h = y2 - existing_box.y\n",
        "        existing_box.freq += 1\n",
        "        rgb_to_stat[box_color] = existing_box\n",
        "      else:\n",
        "        rgb_to_stat[box_color] = box_cmap(x, y, 0, 0, 1)\n",
        "\n",
        "  # filter boxes with small segmentation maps\n",
        "  return {box_color: box_stat for box_color, box_stat in rgb_to_stat.items() if box_stat.freq >= min_segmentation_pixels}\n",
        "\n",
        "\n",
        "def image_to_boxes_by_color_vectorized(image_path: str):\n",
        "  \"\"\"take a colormap segmentation image and infer the bounding boxes by color\"\"\"\n",
        "  if not os.path.isfile(image_path):\n",
        "    raise Exception(f'File not found: {image_path}')\n",
        "  im = Image.open(image_path)\n",
        "  pixels = np.array(im)[:, :, :-1]\n",
        "  width, height = im.size\n",
        "\n",
        "  # ignore the green background color...\n",
        "  bgc = np.array([55, 181, 57])\n",
        "  forground_x, forground_y = np.where(np.all(pixels != bgc, axis=-1))\n",
        "  print(forground_x.shape)\n",
        "  print(forground_y.shape)\n",
        "\n",
        "  rgb_to_stat = dict()\n",
        "  for x in forground_x:\n",
        "    for y in forground_y:\n",
        "      box_color = (pixels[x, y][0], pixels[x, y][1], pixels[x, y][2])\n",
        "\n",
        "      if box_color in rgb_to_stat:\n",
        "        existing_box = rgb_to_stat[box_color]\n",
        "        existing_box.x = min(existing_box.x, x)\n",
        "        existing_box.y = min(existing_box.y, y)\n",
        "\n",
        "        existing_box.w = max(existing_box.w, x - existing_box.x)\n",
        "        existing_box.h = max(existing_box.h, y - existing_box.y)\n",
        "        rgb_to_stat[box_color] = existing_box\n",
        "      else:\n",
        "        rgb_to_stat[box_color] = box_cmap(x, y, 0, 0)\n",
        "  return rgb_to_stat\n",
        "\n",
        "\n",
        "def hash_values(input_list):\n",
        "    \"\"\"\n",
        "    maps/codes a list into integers\n",
        "    :param input_list: enumerable of hashable elements\n",
        "    \"\"\"\n",
        "    hash_map = dict()\n",
        "    for val in input_list:\n",
        "        hash_map[val] = hash_map.get(val, len(hash_map))\n",
        "    return [hash_map[val] for val in input_list]\n",
        "\n",
        "\n",
        "def frames_to_mot15(frames: list) -> None:\n",
        "  \"\"\"take a repo of frames and serialize it in MOT15 standard\"\"\"\n",
        "  video_boxes = []\n",
        "  colors = set()\n",
        "  for frame_path in frames:\n",
        "    frame_detections = image_to_boxes_by_color_loop(frame_path)\n",
        "    video_boxes.append(frame_detections)\n",
        "    colors |= set(frame_detections.keys())\n",
        "\n",
        "  ordered_colors = list(colors)\n",
        "  color_to_id = {color: index for color, index in zip(ordered_colors, hash_values(ordered_colors))}\n",
        "\n",
        "  lines = []\n",
        "  for frame_number, frame_boxes in enumerate(video_boxes):\n",
        "    for rgb_color, box in frame_boxes.items():\n",
        "      # ignore small boxes\n",
        "      if min(box.h, box.w) < min_box_side or box.area() < min_box_area:\n",
        "        continue\n",
        "\n",
        "      pid = color_to_id[rgb_color]\n",
        "      lines.append(','.join([str(frame_number), str(pid), str(box.x), str(box.y), str(box.w), str(box.h), \"1\", \"-1\", \"-1\", \"-1\"]) + \"\\n\")\n",
        "  return lines\n",
        "\n",
        "# group segmentations by cams\n",
        "video_repository = os.path.join(dump_path, 'seg')\n",
        "seg_images = os.listdir(video_repository)\n",
        "cam_to_segs = dict()\n",
        "for seg_name in seg_images:\n",
        "  cam_id = int(seg_name.split('_')[1])\n",
        "  cam_to_segs[cam_id] = cam_to_segs.get(cam_id, []) + [seg_name]\n",
        "\n",
        "\n",
        "for cam_id, unordered_frame_names_single_cam in cam_to_segs.items():\n",
        "  # order by frame id\n",
        "  ordered_names = sorted(unordered_frame_names_single_cam, key=lambda f: int(f.split('_')[2]))\n",
        "  ordered_frame_paths = [os.path.join(video_repository, f) for f in ordered_names]\n",
        "  print(f'Start analyzing cam id: {cam_id} with {len(ordered_frame_paths)} frames: {ordered_frame_paths[:10]}...')\n",
        "\n",
        "  lines = frames_to_mot15(ordered_frame_paths)\n",
        "\n",
        "  # serialize:\n",
        "  mot_challenge_csv_path = os.path.join(output_dir, f'cam_id_{cam_id}.csv')\n",
        "  with open(mot_challenge_csv_path, 'w') as csv_writer:\n",
        "    csv_writer.writelines(lines)\n",
        "\n",
        "print('DONE!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DL8AzQiLVaL"
      },
      "source": [
        "# **Evaluate with ByteTrack**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCTXC8MeLblX"
      },
      "outputs": [],
      "source": [
        "from loguru import logger\n",
        "from typing import List\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.nn.parallel import DistributedDataParallel as DDP\n",
        "\n",
        "from yolox.core import launch\n",
        "from yolox.exp import get_exp\n",
        "from yolox.utils import configure_nccl, fuse_model, get_local_rank, get_model_info, setup_logger\n",
        "from yolox.evaluators import MOTEvaluator\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import warnings\n",
        "import glob\n",
        "import motmetrics as mm\n",
        "from collections import OrderedDict\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def compare_dataframes(gts, ts):\n",
        "    accs = []\n",
        "    names = []\n",
        "    for k, tsacc in ts.items():\n",
        "        if k in gts:            \n",
        "            logger.info('Comparing {}...'.format(k))\n",
        "            accs.append(mm.utils.compare_to_groundtruth(gts[k], tsacc, 'iou', distth=0.5))\n",
        "            names.append(k)\n",
        "        else:\n",
        "            logger.warning('No ground truth for {}, skipping.'.format(k))\n",
        "\n",
        "    return accs, names\n",
        "\n",
        "\n",
        "def evaluate_mota():\n",
        "    # evaluate MOTA\n",
        "    mm.lap.default_solver = 'lap'\n",
        "\n",
        "    # gt_type = ''\n",
        "    gtfiles = glob.glob(os.path.join(output_dir, 'cam_id_*.csv'))\n",
        "    print('gt_files', gtfiles)\n",
        "    tsfiles = glob.glob(os.path.join(output_dir, 'pred_cam_*.txt'))\n",
        "\n",
        "    logger.info('Found {} groundtruths and {} test files.'.format(len(gtfiles), len(tsfiles)))\n",
        "    logger.info('Available LAP solvers {}'.format(mm.lap.available_solvers))\n",
        "    logger.info('Default LAP solver \\'{}\\''.format(mm.lap.default_solver))\n",
        "    logger.info('Loading files.')\n",
        "\n",
        "    gt = OrderedDict([(f.split('.')[-2].split('_')[-1], mm.io.loadtxt(f, fmt='mot15-2D', min_confidence=1)) for f in gtfiles])\n",
        "    ts = OrderedDict([(os.path.splitext(Path(f).parts[-1])[0].split('_')[-1], mm.io.loadtxt(f, fmt='mot15-2D', min_confidence=-1.0)) for f in tsfiles])    \n",
        "\n",
        "    mh = mm.metrics.create()    \n",
        "    accs, names = compare_dataframes(gt, ts)\n",
        "\n",
        "    logger.info('Running metrics')\n",
        "    metrics = ['recall', 'precision', 'num_unique_objects', 'mostly_tracked',\n",
        "                'partially_tracked', 'mostly_lost', 'num_false_positives', 'num_misses',\n",
        "                'num_switches', 'num_fragmentations', 'mota', 'motp', 'num_objects']\n",
        "    summary = mh.compute_many(accs, names=names, metrics=metrics, generate_overall=True)\n",
        "    div_dict = {\n",
        "        'num_objects': ['num_false_positives', 'num_misses', 'num_switches', 'num_fragmentations'],\n",
        "        'num_unique_objects': ['mostly_tracked', 'partially_tracked', 'mostly_lost']}\n",
        "    for divisor in div_dict:\n",
        "        for divided in div_dict[divisor]:\n",
        "            summary[divided] = (summary[divided] / summary[divisor])\n",
        "    fmt = mh.formatters\n",
        "    change_fmt_list = ['num_false_positives', 'num_misses', 'num_switches', 'num_fragmentations', 'mostly_tracked',\n",
        "                        'partially_tracked', 'mostly_lost']\n",
        "    for k in change_fmt_list:\n",
        "        fmt[k] = fmt['mota']\n",
        "    print(mm.io.render_summary(summary, formatters=fmt, namemap=mm.io.motchallenge_metric_names))\n",
        "\n",
        "    metrics = mm.metrics.motchallenge_metrics + ['num_objects']\n",
        "    summary = mh.compute_many(accs, names=names, metrics=metrics, generate_overall=True)\n",
        "    print(mm.io.render_summary(summary, formatters=mh.formatters, namemap=mm.io.motchallenge_metric_names))\n",
        "    logger.info('Completed')\n",
        "\n",
        "def filter_mot_csv_by_area(file_paths: List[str], min_area: int):\n",
        "    if min_area <= 1:\n",
        "      return\n",
        "    \n",
        "    for f_path in file_paths:\n",
        "      with open(f_path, 'r') as csv_reader:\n",
        "        lines = csv_reader.readlines()\n",
        "\n",
        "      filtered_lines = []\n",
        "      for line in lines:\n",
        "        line_fields = line.split(',')\n",
        "        b_w = float(line_fields[4])\n",
        "        b_h = float(line_fields[5])\n",
        "        b_area = b_w * b_h\n",
        "        if b_area >= min_area:\n",
        "          filtered_lines.append(line)\n",
        "\n",
        "      with open(f_path, 'w') as csv_writer:\n",
        "        csv_writer.writelines(filtered_lines)\n",
        "\n",
        "\n",
        "# Filter by few box sizes and evaluate\n",
        "minimal_bbox_area = min_box_area\n",
        "print('#'*20+f' Running evaluation with min area {minimal_bbox_area} '+'#'*20)\n",
        "print(f'Dataset: {dump_path}')\n",
        "\n",
        "# filter gt\n",
        "gt_files = glob.glob(os.path.join(output_dir, 'cam_id_*.csv'))\n",
        "filter_mot_csv_by_area(gt_files, minimal_bbox_area)\n",
        "\n",
        "# filter prediction\n",
        "prediction_files = glob.glob(os.path.join(output_dir, 'pred_cam_*.txt'))\n",
        "filter_mot_csv_by_area(prediction_files, minimal_bbox_area)\n",
        "\n",
        "# evaluate\n",
        "evaluate_mota()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "OQ98fFTvtB4i",
        "hNEjogF5s35O"
      ],
      "name": "CityLifeSimMotEvaluation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}